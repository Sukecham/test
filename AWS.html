AWS 生成AI安全対策ガイド
初心者のためのわかりやすい解説
このガイドについて
AIツールの使い方を「誰が何をどこまで管理するのか」という観点で5段階に分け、それぞれの段階で気をつけるべきことをわかりやすく解説します。
最近では「AIに不適切な指示を出す」「AIの学習データを改ざんする」といった新しい問題が増えています。このガイドでは、そのような問題からどう身を守るかをご説明します。
AIツールの5つの利用形態
AIツールの使い方は大きく分けて以下の5段階があります。段階が上がるほど自由度が増しますが、同時にお金や専門知識、責任も増えていきます。

一般向けAIサービス

企業向けAIサービス

既存AIモデルの利用

AIの調整・カスタマイズ

AIの独自開発

一般向けAIサービス
1
		無料や一般公開されているAIを使う形態
		手軽で費用がかからないという良い点がある
		社内情報の漏えいや無断でのAI利用が心配
		会社は使い方のルール作りと教育が主な役割

企業向けAIサービス
2
		業務用ソフトに組み込まれたAI機能の形態
		サービス保証や契約による保護がある
		特定会社の製品に依存したり、他社との情報混同が心配
		会社は提供会社の評価と契約内容の確認が主な役割

既存AIモデルの利用
3
		AWSなどが提供するAI接続サービスで自社システムを作る形態
		自社の資料をAIに追加して使える良さがある
		AIへの指示内容やアクセス鍵の漏えいが心配
		会社はアクセス管理と安全な指示の確認が主な役割

AIの調整・カスタマイズ
4
		自社の資料でAIの動きを調整する形態
		自社分野での精度が上がる良さがある
		社内情報がAIに取り込まれたり、偏ったAIになる心配
		会社は教える資料の選別とAIの保護が主な役割

AIの独自開発
5
		ゼロから自社AIを開発・運用する形態
		完全に自社でコントロールできる良さがある
		すべての面で自社の責任となる
		会社はAIの開発と運用の全管理が主な役割
各段階で気をつけるべきこと
AIの使い方の段階ごとに、特に気をつけるべきポイントは以下のとおりです。段階が上がるにつれて、必要な対策も増えていきます。
変化のポイント
主な注意点
すべての段階で共通
必要最小限のアクセス権限・データの暗号化・操作記録の保存はどの段階でも必要
段階1→2への変化
"AIに入力する情報の管理"から"AIサービス提供会社の管理"へ重点が移る。契約内容の確認が重要
段階2→3への変化
AIとの接続箇所が増えるため、アクセス権限の設定とAIへの指示内容の確認が重要
段階3→4への変化
社内データの管理が極めて重要に。個人情報の匿名化・データ品質の確認・AIの更新管理
段階4→5への変化
システム開発の安全対策をAIにも拡張。AIの学習環境全体の安全確保が必要
AWSの安全対策ツールとの連携
AWSが提供している安全対策ツールとAIの安全性確保の関係は以下のとおりです。
AWSの仕組み
具体的な使い方
AWSの設計ガイドライン
(生成AIレンズ)
GENSEC01~06という項目で アクセス管理、安全な接続、安全柵 などを段階的に適用する方法を紹介
クラウド導入
フレームワーク (CAF)
統治の観点＝社内ルール整備／安全性の観点＝リスク対策の実施
MITRE ATLAS
(AI脅威対策集)
AML.M0015（悪意ある入力の検出）を段階3-5の保護機能で実現
実施のための段階的なステップ（推奨）
1
AIの使い道と必要な保護レベルの決定
AIで何をしたいか、扱うデータの重要度、自社開発が必要かを検討します。
2
小さく始めてみる
まずは小規模に（多くは段階2または3から）試してみて、リスクと効果を確認します。
3
ルール作りと教育
社内でのAI利用ルールを作り、教育を行い、無断でのAI利用を防止します。
4
段階的な拡張
成熟度と必要性に応じて段階4→5へ進み、AIの開発・運用の管理体制を段階的に整えます。
5
継続的モニタリング
継続的モニタリングで新たな脅威・規制・モデル更新に追随します。
まとめ
スコーピングマトリックスは「何を守るか」を整理するレンズです。AWS Well-Architectedや生成AIレンズは「どう守るか」の実装ガイドを提供します。
スコープは固定ではなく、ユースケース・リスク許容度に合わせて可変です。最終的な差別化要因は「信頼」であり、明確な責任区分と堅牢なデータガバナンスが、安全かつ持続的な生成AI活用を後押しします。
AWS 生成AIセキュリティ-スコーピングマトリックス ─ 速習ダイジェスト
